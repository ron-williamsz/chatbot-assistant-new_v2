# Guia: Aumentar Limite de Upload de 100MB para 1GB + Corrigir Timeouts

Este documento cont√©m instru√ß√µes COMPLETAS para aumentar o limite de upload de arquivos de √°udio de 100MB para 1GB e corrigir todos os timeouts no servidor de produ√ß√£o.

## üìã √çndice

- [PARTE 1: Aumentar Limite de Upload](#parte-1-aumentar-limite-de-upload)
- [PARTE 2: Corrigir Timeouts](#parte-2-corrigir-timeouts-para-arquivos-grandes)
- [Comandos Completos](#comandos-completos-para-aplicar-no-servidor)
- [Verifica√ß√£o e Testes](#verifica√ß√£o-p√≥s-deploy)

---

# PARTE 1: Aumentar Limite de Upload

## Arquivos que precisam ser modificados

### 1. Frontend - Template HTML
**Arquivo:** `app/templates/admin/transcricao.html`

**Linha 134:** Alterar texto informativo
```html
<!-- DE: -->
<p class="text-xs text-gray-400 mt-2">Formatos suportados: MP3, WAV, M4A, FLAC, OGG, OPUS (m√°x. 100MB)</p>

<!-- PARA: -->
<p class="text-xs text-gray-400 mt-2">Formatos suportados: MP3, WAV, M4A, FLAC, OGG, OPUS (m√°x. 1GB)</p>
```

**Linha 326:** Alterar valida√ß√£o JavaScript
```javascript
// DE:
const maxSize = 100 * 1024 * 1024; // 100MB

// PARA:
const maxSize = 1024 * 1024 * 1024; // 1GB
```

**Linha 341:** Alterar mensagem de erro
```javascript
// DE:
if (file.size > maxSize) {
    alert('Arquivo muito grande. M√°ximo 100MB.');
    return;
}

// PARA:
if (file.size > maxSize) {
    alert('Arquivo muito grande. M√°ximo 1GB.');
    return;
}
```

### 2. Backend - Configura√ß√£o Flask
**Arquivo:** `app/__init__.py`

**Ap√≥s linha 15:** Adicionar configura√ß√£o de limite de upload
```python
app.secret_key = os.getenv('FLASK_SECRET_KEY', 'dev-secret-key')

# Configurar limite de upload para 1GB
app.config['MAX_CONTENT_LENGTH'] = int(os.getenv('MAX_CONTENT_LENGTH', 1024)) * 1024 * 1024

# Configura√ß√µes para trabalhar corretamente com Cloudflared/proxy
app.config['PREFERRED_URL_SCHEME'] = 'https'
```

### 3. Nginx - Configura√ß√£o de Proxy
**Arquivo:** `nginx.conf`

**Ap√≥s linha 26:** Adicionar limite de upload no bloco http
```nginx
# Gzip compression
gzip on;
gzip_vary on;
gzip_min_length 1024;
gzip_types text/plain text/css text/xml text/javascript application/javascript application/xml+rss application/json;

# Aumentar limite de upload para 1GB
client_max_body_size 1024M;

# Security headers
```

### 4. Vari√°veis de Ambiente
**Arquivo:** `production.env.example` (linha 87-88)

```bash
# DE:
# Tamanho m√°ximo de upload em MB
MAX_CONTENT_LENGTH=16

# PARA:
# Tamanho m√°ximo de upload em MB (1024 = 1GB)
MAX_CONTENT_LENGTH=1024
```

**Arquivo de produ√ß√£o:** `.env` (criar/atualizar no servidor)
```bash
# Adicionar ou atualizar esta linha:
MAX_CONTENT_LENGTH=1024
```

## Comandos para aplicar no servidor

### Passo 1: Fazer backup dos arquivos
```bash
cd /caminho/do/projeto
cp app/templates/admin/transcricao.html app/templates/admin/transcricao.html.backup
cp app/__init__.py app/__init__.py.backup
cp nginx.conf nginx.conf.backup
cp .env .env.backup
```

### Passo 2: Aplicar as altera√ß√µes
Edite os arquivos conforme descrito acima usando `nano`, `vim` ou outro editor:

```bash
# Editar template HTML
nano app/templates/admin/transcricao.html

# Editar configura√ß√£o Flask
nano app/__init__.py

# Editar configura√ß√£o Nginx
nano nginx.conf

# Atualizar vari√°vel de ambiente
nano .env
```

### Passo 3: Reiniciar os servi√ßos
```bash
# Se estiver usando Docker Compose:
docker-compose restart

# Ou reiniciar servi√ßos espec√≠ficos:
docker-compose restart chatbot-assistant
docker-compose restart nginx

# Verificar logs para confirmar que n√£o h√° erros:
docker-compose logs -f chatbot-assistant
docker-compose logs -f nginx
```

### Passo 4: Verificar se as altera√ß√µes funcionaram
```bash
# Verificar configura√ß√£o do Nginx
docker-compose exec nginx nginx -t

# Verificar logs da aplica√ß√£o
docker-compose logs -f chatbot-assistant

# Testar upload de arquivo grande (se poss√≠vel)
```

## Verifica√ß√£o p√≥s-deploy

1. Acesse a interface de transcri√ß√£o
2. Verifique se o texto mostra "m√°x. 1GB" em vez de "m√°x. 100MB"
3. Teste o upload de um arquivo maior que 100MB (mas menor que 1GB)
4. Confirme que o arquivo √© aceito e processado corretamente

## Rollback (se necess√°rio)

Se algo der errado, restaure os backups:

```bash
cp app/templates/admin/transcricao.html.backup app/templates/admin/transcricao.html
cp app/__init__.py.backup app/__init__.py
cp nginx.conf.backup nginx.conf
cp .env.backup .env
docker-compose restart
```

## Resumo das altera√ß√µes

| Arquivo | Linha | Altera√ß√£o |
|---------|-------|-----------|
| `transcricao.html` | 134 | Texto: "m√°x. 100MB" ‚Üí "m√°x. 1GB" |
| `transcricao.html` | 326 | JavaScript: `100 * 1024 * 1024` ‚Üí `1024 * 1024 * 1024` |
| `transcricao.html` | 341 | Mensagem: "M√°ximo 100MB" ‚Üí "M√°ximo 1GB" |
| `app/__init__.py` | ~17-18 | Adicionar `MAX_CONTENT_LENGTH = 1GB` |
| `nginx.conf` | ~29 | Adicionar `client_max_body_size 1024M;` |
| `.env` | - | `MAX_CONTENT_LENGTH=1024` |

## PARTE 2: CORRIGIR TIMEOUTS PARA ARQUIVOS GRANDES

### Problema identificado
Mesmo com o limite de 1GB configurado, arquivos acima de 250MB estavam falhando com erro:
```
Timeout ap√≥s 300 segundos. Tente novamente com um arquivo menor.
```

### Arquivos de timeout que precisam ser ajustados

#### 5. Timeout de polling - `app/routes.py`
**Linha 3562:** Aumentar tempo m√°ximo de espera
```python
# DE:
max_wait_time = 300  # 5 minutos

# PARA:
max_wait_time = 3600  # 60 minutos (1 hora) para arquivos grandes
```

#### 6. Timeouts do Nginx - `nginx.conf`
**Linhas 68-73 e 125-130:** Aumentar todos os timeouts (aparecem 2 vezes no arquivo)
```nginx
# DE:
# Timeouts
proxy_connect_timeout 30s;
proxy_send_timeout 30s;
proxy_read_timeout 30s;

# PARA:
# Timeouts (aumentados para suportar uploads e processamento de arquivos grandes)
proxy_connect_timeout 60s;
proxy_send_timeout 3600s;
proxy_read_timeout 3600s;
```

#### 7. Timeout do Gunicorn - `Dockerfile`
**Linha 51:** Aumentar timeout do worker
```dockerfile
# DE:
CMD ["sh", "-c", "gunicorn --bind 0.0.0.0:${PORT} --workers ${WORKERS} --threads 2 --timeout 120 --access-logfile /app/logs/access.log --error-logfile /app/logs/error.log --log-level info wsgi:app"]

# PARA:
CMD ["sh", "-c", "gunicorn --bind 0.0.0.0:${PORT} --workers ${WORKERS} --threads 2 --timeout 3600 --access-logfile /app/logs/access.log --error-logfile /app/logs/error.log --log-level info wsgi:app"]
```

#### 8. Timeout de upload - `app/services/transcriber_client.py`
**Linha 18:** Aumentar timeout de upload
```python
# DE:
self.timeout = 30

# PARA:
self.timeout = 600  # 10 minutos para upload de arquivos grandes
```

### ‚úÖ Configura√ß√µes que J√Å EST√ÉO CORRETAS

#### Celery Worker - `docker-compose.yml` (linha 105)
```yaml
command: ["celery", "-A", "tasks", "worker", "--loglevel=info", "--time-limit=7200", "--soft-time-limit=7000", "--concurrency=2"]
```
‚úÖ **2 horas** de limite - suficiente para processar arquivos grandes

#### Redis - `docker-compose.yml` (linha 146)
```yaml
--maxmemory 256mb
```
‚úÖ Redis apenas armazena metadados, n√£o os arquivos completos

### Resumo completo de timeouts

| Componente | Antes | Depois | Motivo |
|------------|-------|--------|--------|
| Polling (routes.py) | 300s (5min) | 3600s (1h) | Tempo de espera pelo processamento |
| Nginx read_timeout | 30s | 3600s (1h) | Aguardar resposta do backend |
| Nginx send_timeout | 30s | 3600s (1h) | Envio de dados grandes |
| Nginx connect_timeout | 30s | 60s | Estabelecer conex√£o |
| Gunicorn timeout | 120s (2min) | 3600s (1h) | Worker processar requisi√ß√£o |
| Upload timeout | 30s | 600s (10min) | Upload de arquivo grande |
| Celery worker | 7200s (2h) | 7200s (2h) | ‚úÖ J√° adequado |

---

# üöÄ GUIA PASSO A PASSO PARA APLICAR NO SERVIDOR

## ‚ö†Ô∏è ATEN√á√ÉO ANTES DE COME√áAR

**IMPORTANTE:** Este guia faz 10 altera√ß√µes em 7 arquivos diferentes. Leia tudo antes de come√ßar!

### Pr√©-requisitos
- Acesso SSH ao servidor
- Permiss√µes para editar arquivos e executar Docker
- Tempo estimado: 20-30 minutos
- **Downtime:** Sim, ~2-3 minutos durante o rebuild

---

## üìù PASSO 1: Conectar ao Servidor e Fazer Backup

```bash
# Conectar ao servidor
ssh usuario@seu-servidor.com

# Navegar at√© o diret√≥rio do projeto
cd /var/www/chatbot-assistant-new
# OU o caminho onde seu projeto est√°

# FAZER BACKUP DE TODOS OS ARQUIVOS
cp app/templates/admin/transcricao.html app/templates/admin/transcricao.html.backup
cp app/__init__.py app/__init__.py.backup
cp app/routes.py app/routes.py.backup
cp app/services/transcriber_client.py app/services/transcriber_client.py.backup
cp nginx.conf nginx.conf.backup
cp Dockerfile Dockerfile.backup
cp .env .env.backup 2>/dev/null || echo ".env n√£o existe, ser√° criado"

# Verificar se os backups foram criados
ls -la *.backup app/*.backup app/templates/admin/*.backup app/services/*.backup
```

---

## üìù PASSO 2: Editar Arquivo 1 - Frontend (transcricao.html)

```bash
nano app/templates/admin/transcricao.html
```

**Altera√ß√£o 1 (Linha ~134):** Pressione `Ctrl+W` para buscar, digite `m√°x. 100MB` e altere:
```html
DE:  <p class="text-xs text-gray-400 mt-2">Formatos suportados: MP3, WAV, M4A, FLAC, OGG, OPUS (m√°x. 100MB)</p>
PARA: <p class="text-xs text-gray-400 mt-2">Formatos suportados: MP3, WAV, M4A, FLAC, OGG, OPUS (m√°x. 1GB)</p>
```

**Altera√ß√£o 2 (Linha ~326):** Pressione `Ctrl+W`, busque `const maxSize = 100` e altere:
```javascript
DE:  const maxSize = 100 * 1024 * 1024; // 100MB
PARA: const maxSize = 1024 * 1024 * 1024; // 1GB
```

**Altera√ß√£o 3 (Linha ~341):** Pressione `Ctrl+W`, busque `M√°ximo 100MB` e altere:
```javascript
DE:  alert('Arquivo muito grande. M√°ximo 100MB.');
PARA: alert('Arquivo muito grande. M√°ximo 1GB.');
```

Salvar: `Ctrl+O`, `Enter`, Sair: `Ctrl+X`

---

## üìù PASSO 3: Editar Arquivo 2 - Configura√ß√£o Flask (__init__.py)

```bash
nano app/__init__.py
```

**Altera√ß√£o 4 (Ap√≥s linha ~15):** Adicionar DUAS novas linhas ap√≥s `app.secret_key = ...`
```python
app.secret_key = os.getenv('FLASK_SECRET_KEY', 'dev-secret-key')

# Configurar limite de upload para 1GB
app.config['MAX_CONTENT_LENGTH'] = int(os.getenv('MAX_CONTENT_LENGTH', 1024)) * 1024 * 1024

# Configura√ß√µes para trabalhar corretamente com Cloudflared/proxy
```

Salvar: `Ctrl+O`, `Enter`, Sair: `Ctrl+X`

---

## üìù PASSO 4: Editar Arquivo 3 - Timeout de Polling (routes.py)

```bash
nano app/routes.py
```

**Altera√ß√£o 5 (Linha ~3562):** Pressione `Ctrl+W`, busque `max_wait_time = 300` e altere:
```python
DE:  max_wait_time = 300  # 5 minutos
PARA: max_wait_time = 3600  # 60 minutos (1 hora) para arquivos grandes
```

Salvar: `Ctrl+O`, `Enter`, Sair: `Ctrl+X`

---

## üìù PASSO 5: Editar Arquivo 4 - Timeout de Upload (transcriber_client.py)

```bash
nano app/services/transcriber_client.py
```

**Altera√ß√£o 6 (Linha ~18):** Pressione `Ctrl+W`, busque `self.timeout = 30` e altere:
```python
DE:  self.timeout = 30
PARA: self.timeout = 600  # 10 minutos para upload de arquivos grandes
```

Salvar: `Ctrl+O`, `Enter`, Sair: `Ctrl+X`

---

## üìù PASSO 6: Editar Arquivo 5 - Nginx (nginx.conf)

```bash
nano nginx.conf
```

**Altera√ß√£o 7 (Ap√≥s linha ~26):** Adicionar DUAS linhas ap√≥s `gzip_types ...`:
```nginx
gzip_types text/plain text/css text/xml text/javascript application/javascript application/xml+rss application/json;

# Aumentar limite de upload para 1GB
client_max_body_size 1024M;

# Security headers
```

**Altera√ß√£o 8 (Linhas ~68-73):** Buscar primeiro bloco de timeouts e alterar:
```nginx
DE:
# Timeouts
proxy_connect_timeout 30s;
proxy_send_timeout 30s;
proxy_read_timeout 30s;

PARA:
# Timeouts (aumentados para suportar uploads e processamento de arquivos grandes)
proxy_connect_timeout 60s;
proxy_send_timeout 3600s;
proxy_read_timeout 3600s;
```

**Altera√ß√£o 9 (Linhas ~125-130):** Buscar segundo bloco de timeouts (mais abaixo no arquivo) e fazer a MESMA altera√ß√£o:
```nginx
DE:
# Timeouts
proxy_connect_timeout 30s;
proxy_send_timeout 30s;
proxy_read_timeout 30s;

PARA:
# Timeouts (aumentados para suportar uploads e processamento de arquivos grandes)
proxy_connect_timeout 60s;
proxy_send_timeout 3600s;
proxy_read_timeout 3600s;
```

Salvar: `Ctrl+O`, `Enter`, Sair: `Ctrl+X`

---

## üìù PASSO 7: Editar Arquivo 6 - Gunicorn Timeout (Dockerfile)

```bash
nano Dockerfile
```

**Altera√ß√£o 10 (Linha ~51):** Buscar `--timeout 120` e alterar:
```dockerfile
DE:  CMD ["sh", "-c", "gunicorn --bind 0.0.0.0:${PORT} --workers ${WORKERS} --threads 2 --timeout 120 --access-logfile /app/logs/access.log --error-logfile /app/logs/error.log --log-level info wsgi:app"]

PARA: CMD ["sh", "-c", "gunicorn --bind 0.0.0.0:${PORT} --workers ${WORKERS} --threads 2 --timeout 3600 --access-logfile /app/logs/access.log --error-logfile /app/logs/error.log --log-level info wsgi:app"]
```

Salvar: `Ctrl+O`, `Enter`, Sair: `Ctrl+X`

---

## üìù PASSO 8: Editar/Criar Arquivo 7 - Vari√°vel de Ambiente (.env)

```bash
# Verificar se .env existe
ls -la .env

# Se existir, editar
nano .env

# Se n√£o existir, criar a partir do exemplo
cp production.env.example .env
nano .env
```

**Adicionar ou alterar esta linha:**
```bash
MAX_CONTENT_LENGTH=1024
```

Salvar: `Ctrl+O`, `Enter`, Sair: `Ctrl+X`

---

## üìù PASSO 9: Verificar Todas as Altera√ß√µes

```bash
# Verificar se todas as altera√ß√µes foram feitas
echo "=== Verificando altera√ß√µes ==="

# 1. Verificar transcricao.html
echo "1. Verificando frontend (deve mostrar 1GB):"
grep "m√°x. 1GB" app/templates/admin/transcricao.html
grep "1024 \* 1024 \* 1024" app/templates/admin/transcricao.html

# 2. Verificar __init__.py
echo "2. Verificando Flask config (deve mostrar MAX_CONTENT_LENGTH):"
grep "MAX_CONTENT_LENGTH" app/__init__.py

# 3. Verificar routes.py
echo "3. Verificando timeout de polling (deve mostrar 3600):"
grep "max_wait_time = 3600" app/routes.py

# 4. Verificar transcriber_client.py
echo "4. Verificando timeout de upload (deve mostrar 600):"
grep "self.timeout = 600" app/services/transcriber_client.py

# 5. Verificar nginx.conf
echo "5. Verificando nginx (deve mostrar 1024M e 3600s):"
grep "client_max_body_size 1024M" nginx.conf
grep "proxy_read_timeout 3600s" nginx.conf

# 6. Verificar Dockerfile
echo "6. Verificando Gunicorn (deve mostrar timeout 3600):"
grep "timeout 3600" Dockerfile

# 7. Verificar .env
echo "7. Verificando .env:"
grep "MAX_CONTENT_LENGTH" .env

echo "=== Verifica√ß√£o completa! ==="
```

---

## üìù PASSO 10: Rebuild e Restart (DOWNTIME ~2-3 minutos)

```bash
# ATEN√á√ÉO: Os comandos abaixo v√£o derrubar o servi√ßo temporariamente!

# Parar todos os containers
docker-compose down

# Rebuild do container principal (necess√°rio por causa do Dockerfile)
docker-compose build --no-cache chatbot-assistant

# Subir todos os servi√ßos
docker-compose up -d

# Aguardar containers iniciarem
sleep 10

# Verificar status
docker-compose ps
```

---

## üìù PASSO 11: Verificar Logs

```bash
# Verificar se h√° erros nos logs
echo "=== Logs do chatbot-assistant ==="
docker-compose logs --tail=50 chatbot-assistant

echo "=== Logs do nginx ==="
docker-compose logs --tail=50 nginx

echo "=== Logs do transcrever ==="
docker-compose logs --tail=50 transcrever-new

# Testar configura√ß√£o do Nginx
docker-compose exec nginx nginx -t
```

---

## üìù PASSO 12: Teste Final

```bash
# Verificar health dos servi√ßos
curl http://localhost:5359/health
curl http://localhost:3024/healthcheck

# Se tudo estiver OK, voc√™ ver√°:
# {"status": "ok"} ou similar
```

## Resumo das altera√ß√µes COMPLETO

| Arquivo | Linha | Altera√ß√£o | Tipo |
|---------|-------|-----------|------|
| `transcricao.html` | 134 | "m√°x. 100MB" ‚Üí "m√°x. 1GB" | Limite |
| `transcricao.html` | 326 | `100 * 1024 * 1024` ‚Üí `1024 * 1024 * 1024` | Limite |
| `transcricao.html` | 341 | "M√°ximo 100MB" ‚Üí "M√°ximo 1GB" | Limite |
| `app/__init__.py` | ~17-18 | Adicionar `MAX_CONTENT_LENGTH = 1GB` | Limite |
| `nginx.conf` | ~29 | `client_max_body_size 1024M;` | Limite |
| `app/routes.py` | 3562 | `300` ‚Üí `3600` segundos | Timeout |
| `nginx.conf` | 68-73 | Timeouts de 30s ‚Üí 3600s | Timeout |
| `nginx.conf` | 125-130 | Timeouts de 30s ‚Üí 3600s | Timeout |
| `Dockerfile` | 51 | Gunicorn timeout `120` ‚Üí `3600` | Timeout |
| `transcriber_client.py` | 18 | `timeout = 30` ‚Üí `600` | Timeout |
| `.env` | - | `MAX_CONTENT_LENGTH=1024` | Limite |

---

## üéØ Teste na Interface Web

1. Acesse o painel de transcri√ß√£o: `https://seu-dominio.com/admin/transcricao`
2. Tente fazer upload de um arquivo de √°udio com mais de 100MB
3. Verifique se o texto mostra "m√°x. 1GB"
4. Inicie a transcri√ß√£o e monitore o progresso
5. Arquivos grandes (250MB+) podem levar 15-30 minutos para processar

---

## üîÑ Rollback (se algo der errado)

```bash
# Restaurar todos os arquivos dos backups
cp app/templates/admin/transcricao.html.backup app/templates/admin/transcricao.html
cp app/__init__.py.backup app/__init__.py
cp app/routes.py.backup app/routes.py
cp app/services/transcriber_client.py.backup app/services/transcriber_client.py
cp nginx.conf.backup nginx.conf
cp Dockerfile.backup Dockerfile
cp .env.backup .env

# Rebuild e restart
docker-compose down
docker-compose build --no-cache chatbot-assistant
docker-compose up -d
```

---

## üìä Checklist de Verifica√ß√£o Final

- [ ] ‚úÖ Backup de todos os arquivos criado
- [ ] ‚úÖ 10 altera√ß√µes aplicadas em 7 arquivos
- [ ] ‚úÖ Script de verifica√ß√£o executado sem erros
- [ ] ‚úÖ Containers rebuilded e reiniciados
- [ ] ‚úÖ Logs verificados (sem erros cr√≠ticos)
- [ ] ‚úÖ Health checks passando
- [ ] ‚úÖ Interface mostra "m√°x. 1GB"
- [ ] ‚úÖ Teste com arquivo > 100MB realizado

---

## ‚ùì Troubleshooting

### Problema: Nginx n√£o inicia ap√≥s restart
**Solu√ß√£o:**
```bash
# Testar configura√ß√£o
docker-compose exec nginx nginx -t

# Se houver erro de sintaxe, restaurar backup
cp nginx.conf.backup nginx.conf
docker-compose restart nginx
```

### Problema: Upload ainda falha com timeout
**Verificar:**
```bash
# Ver se todas as altera√ß√µes de timeout foram aplicadas
grep "3600" app/routes.py Dockerfile nginx.conf
grep "600" app/services/transcriber_client.py

# Se algum n√£o aparecer, refazer a edi√ß√£o
```

### Problema: Erro 413 "Request Entity Too Large"
**Verificar:**
```bash
# Confirmar que client_max_body_size est√° no nginx.conf
grep "client_max_body_size" nginx.conf

# Deve retornar: client_max_body_size 1024M;
```

### Problema: Container n√£o sobe ap√≥s rebuild
**Solu√ß√£o:**
```bash
# Ver logs detalhados
docker-compose logs chatbot-assistant

# Verificar se h√° erro de sintaxe Python
docker-compose exec chatbot-assistant python -m py_compile app/__init__.py
docker-compose exec chatbot-assistant python -m py_compile app/routes.py
```

---

## üìù Observa√ß√µes Importantes

- ‚ö†Ô∏è **Espa√ßo em disco:** Certifique-se de ter pelo menos 10GB livres para processar arquivos de 1GB
- ‚ö†Ô∏è **Rebuild obrigat√≥rio:** Por causa do Dockerfile, o rebuild n√£o √© opcional
- ‚ö†Ô∏è **Tempo de processamento:** Arquivos grandes podem levar at√© 1 hora
- ‚ö†Ô∏è **RAM:** Transcri√ß√µes grandes podem usar at√© 1.5GB de RAM
- ‚ö†Ô∏è **Downtime:** Planeje para ~2-3 minutos de indisponibilidade
- ‚úÖ **Celery e Redis:** J√° estavam corretamente configurados (2 horas de limite)
- üí° **Dica:** Execute as altera√ß√µes em hor√°rio de baixo tr√°fego

---

## üìö Documenta√ß√£o T√©cnica

### Timeouts Configurados

| Camada | Componente | Timeout | Prop√≥sito |
|--------|------------|---------|-----------|
| Frontend | JavaScript | N/A | Valida√ß√£o apenas |
| Upload | transcriber_client | 600s (10min) | Upload do arquivo para microservi√ßo |
| Processing | Celery Worker | 7200s (2h) | Processamento AssemblyAI |
| Polling | routes.py | 3600s (1h) | Aguardar resultado |
| HTTP | Nginx | 3600s (1h) | Proxy reverso |
| WSGI | Gunicorn | 3600s (1h) | Worker Python |

### Fluxo de Upload Completo

1. **Frontend:** Usu√°rio seleciona arquivo (valida√ß√£o 1GB)
2. **Upload:** Arquivo enviado para backend Flask (timeout 600s)
3. **Backend:** Flask salva temporariamente e envia para microservi√ßo
4. **Microservi√ßo:** Recebe arquivo e cria task Celery
5. **Celery Worker:** Processa com AssemblyAI (at√© 7200s)
6. **Polling:** Backend Flask verifica status a cada 3s (at√© 3600s)
7. **Download:** Backend baixa resultado e entrega para usu√°rio
8. **Cleanup:** Arquivos tempor√°rios removidos

---

## ‚úÖ Conclus√£o

Ap√≥s seguir todos os passos, seu servidor estar√° configurado para:

- ‚úÖ Aceitar uploads de at√© **1GB**
- ‚úÖ Processar transcri√ß√µes por at√© **1 hora**
- ‚úÖ Suportar arquivos grandes sem timeout
- ‚úÖ Manter compatibilidade com arquivos pequenos

**Tempo total estimado:** 20-30 minutos
**Downtime:** ~2-3 minutos durante rebuild
**Altera√ß√µes:** 10 modifica√ß√µes em 7 arquivos
